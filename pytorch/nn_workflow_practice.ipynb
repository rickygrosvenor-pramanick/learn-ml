{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF7D5XpX8ODi368XQy7Lqy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickygrosvenor-pramanick/learn-ml/blob/main/pytorch/nn_workflow_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RycF4CzogF8e"
      },
      "outputs": [],
      "source": [
        "# Create Dataset\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "X, y = make_circles(n_samples=1000,\n",
        "                    noise=0.7,\n",
        "                    factor=0.8,\n",
        "                    random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Tensors\n",
        "import torch\n",
        "\n",
        "X = torch.from_numpy(X).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.float)"
      ],
      "metadata": {
        "id": "saSwPWAQgrGr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TaBKyDVBg-BX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agnostic Code\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "KVIAfeXBhWHr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigate Data Format\n",
        "# X gives 2 numbers as input, y returns 1 number as output\n",
        "X_train[:5], y_train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Ts3pSah9Di",
        "outputId": "35e80887-1602-41d7-bb1a-3acc265d8e48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.3037,  0.1872],\n",
              "         [-0.3370, -0.6710],\n",
              "         [-1.4545,  0.4610],\n",
              "         [-0.7890, -0.2558],\n",
              "         [-0.0992,  1.1932]]),\n",
              " tensor([1., 0., 0., 0., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model Class\n",
        "class CircleModelV1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(in_features=2, out_features=8)\n",
        "    self.layer_2 = nn.Linear(in_features=8, out_features=3)\n",
        "    self.layer_3 = nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_3(self.layer_2(self.layer_1(x)))"
      ],
      "metadata": {
        "id": "SOjC6JMchlBh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model Instance\n",
        "model1 = CircleModelV1().to(device)\n",
        "model1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_7zDS6sitO2",
        "outputId": "6bc5bca4-34f6-486f-91f7-32e5dfca3696"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CircleModelV1(\n",
              "  (layer_1): Linear(in_features=2, out_features=8, bias=True)\n",
              "  (layer_2): Linear(in_features=8, out_features=3, bias=True)\n",
              "  (layer_3): Linear(in_features=3, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial Predictions without Training\n",
        "import math\n",
        "with torch.inference_mode():\n",
        "  untrained_preds = model1(X_test.to(device))\n",
        "untrained_preds[:5], y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Rkgb8Gi1_d",
        "outputId": "a509d7a9-3393-48e8-e692-746d1d8e812f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.1718],\n",
              "         [-0.4396],\n",
              "         [-0.1408],\n",
              "         [-0.2943],\n",
              "         [-0.1577]]),\n",
              " tensor([1., 0., 1., 0., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a loss function\n",
        "\n",
        "# For Regression, you may want MSE or MAE\n",
        "# For Classification, Binary Cross Entropy or Categorical Cross Entropy\n",
        "sigmoid = torch.Sigmoid()\n",
        "\n",
        "loss_fn = nn.BCELoss() # requires inputs to have gone through the sigmoid activation function prior to input\n",
        "\n",
        "# loss_fn = nn.BCEWithLogitsLoss() # has sigmoid activation function built in\n",
        "# This is somewhat similar to\n",
        "# nn.Sequential(\n",
        "#     nn.Sigmoid(),\n",
        "#     nn.BCELoss()\n",
        "# )\n",
        "# nn.BCEWithLogitsLoss() is more numerically stable than plain nn.Sigmoid->nn.BCELoss but we'll do it the other way\n",
        "# to get a sense of the work better\n",
        "\n",
        "optimiser = torch.optim.SGD(params=model1.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "o87Aw9o6Zy_x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters getting updated by SGD\n",
        "model1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbAepHKO0a2I",
        "outputId": "3811a683-68cf-477f-e3e4-a05811544b95"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer_1.weight',\n",
              "              tensor([[ 0.6559,  0.6475],\n",
              "                      [-0.2728, -0.0245],\n",
              "                      [-0.6433, -0.2504],\n",
              "                      [-0.2940, -0.4931],\n",
              "                      [ 0.6968, -0.6576],\n",
              "                      [-0.2427,  0.5973],\n",
              "                      [-0.6657, -0.5961],\n",
              "                      [-0.4022,  0.4858]])),\n",
              "             ('layer_1.bias',\n",
              "              tensor([ 0.1872,  0.3923, -0.1614, -0.6161, -0.1182,  0.0104, -0.1730, -0.6483])),\n",
              "             ('layer_2.weight',\n",
              "              tensor([[ 0.2580, -0.1306,  0.3463, -0.1854, -0.0450, -0.1453, -0.0555,  0.0951],\n",
              "                      [ 0.1459, -0.2665,  0.2170,  0.2830, -0.0563, -0.3383,  0.2932,  0.3381],\n",
              "                      [-0.0817, -0.1348,  0.3110,  0.1524,  0.1587, -0.1425, -0.1264,  0.2304]])),\n",
              "             ('layer_2.bias', tensor([-0.3515, -0.1798,  0.0155])),\n",
              "             ('layer_3.weight', tensor([[-0.1521, -0.5621, -0.0147]])),\n",
              "             ('layer_3.bias', tensor([-0.2216]))])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.tensor([1, 2, 3])\n",
        "tensor2 = torch.tensor([1, 9, 3])\n",
        "torch.eq(tensor1, tensor2).sum(), torch.eq(tensor1, tensor2).sum().item(), torch.eq(tensor1, tensor2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJr6NKeOQK64",
        "outputId": "d94a14b7-7f23-4ae9-c19e-ec5a0c4f6fab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2), 2, tensor([ True, False,  True]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Accuracy Function - https://www.youtube.com/watch?v=RYFViaaJxE8&ab_channel=MathsResource as a Percentage\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  accuracy = (correct/len(y_pred)) * 100\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "ky81QeJd0diY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "\n",
        "# Logits are the raw outputs of our models - output from the forward() function of our model class.\n",
        "# We want to go from logits -> prediction probabilities -> prediction label\n",
        "\n",
        "# We can convert Logits into Prediction Probabilities by passing them through an activation function\n",
        "# Generally sigmoid for binary classification and softmax for multiclass classification\n",
        "\n",
        "# Logits from Model Output\n",
        "y_logits = model1(X_test.to(device))\n",
        "\n",
        "# Pass through Sigmoid Function to get Prediction Probabilities\n",
        "y_pred_probs = torch.sigmoid(y_logits)\n",
        "\n",
        "# Round the Prediction Probabilities to get Classification Category or Prediction Label.\n",
        "y_preds = torch.round(y_pred_probs)\n",
        "y_preds[:5], y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrFSE7SkQTz0",
        "outputId": "91ccb6fd-48a8-493e-cadf-be4f87fb5c6f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]], grad_fn=<SliceBackward0>),\n",
              " tensor([1., 0., 1., 0., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As seen from above, y_preds has an extra redundant dimension\n",
        "y_preds.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gj50IhlUVo2",
        "outputId": "9dfaeeee-369c-4f18-cb50-ceda42e5549e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So we squeeze the Tensor\n",
        "y_preds.squeeze()[:5], y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpMKZkOGVQCU",
        "outputId": "fa3ae16c-a4ca-41a4-9457-e0beb2cb0a8e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>),\n",
              " tensor([1., 0., 1., 0., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a Training and Testing Loop\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "# Put data to target device\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model1.train()\n",
        "\n",
        "  # 1. Forward pass (model outputs raw logits)\n",
        "  y_logits = model1(X_train).squeeze()\n",
        "  y_preds = torch.round(torch.sigmoid(y_logits))\n",
        "\n",
        "  # 2. Calculate loss/accuracy - https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html\n",
        "  loss = loss_fn(torch.sigmoid(y_logits), y_train)\n",
        "  accuracy = accuracy_fn(y_true=y_train, y_pred=y_preds)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimiser.zero_grad()\n",
        "\n",
        "  # 4. Loss backwards\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Optimizer step\n",
        "  optimiser.step()\n",
        "\n",
        "  ### Testing\n",
        "  model1.eval()\n",
        "  with torch.inference_mode():\n",
        "    # 1. Forward pass\n",
        "    test_logits = model1(X_test).squeeze()\n",
        "    test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "\n",
        "    # 2. Calculate loss/accuracy\n",
        "    test_loss = loss_fn(torch.sigmoid(test_logits), y_test)\n",
        "    test_accuracy = accuracy_fn(y_true=y_test, y_pred=test_pred)\n",
        "\n",
        "    # Print out what's happening every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {accuracy:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4wMJd2lVVhV",
        "outputId": "08ae2dda-a6c2-4a1f-a245-c08593fed1f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.69860, Accuracy: 49.38% | Test loss: 0.69912, Test acc: 51.50%\n",
            "Epoch: 10 | Loss: 0.69639, Accuracy: 49.75% | Test loss: 0.69718, Test acc: 49.50%\n",
            "Epoch: 20 | Loss: 0.69552, Accuracy: 49.00% | Test loss: 0.69627, Test acc: 51.50%\n",
            "Epoch: 30 | Loss: 0.69501, Accuracy: 49.12% | Test loss: 0.69565, Test acc: 51.00%\n",
            "Epoch: 40 | Loss: 0.69464, Accuracy: 49.75% | Test loss: 0.69519, Test acc: 51.00%\n",
            "Epoch: 50 | Loss: 0.69436, Accuracy: 50.00% | Test loss: 0.69483, Test acc: 52.50%\n",
            "Epoch: 60 | Loss: 0.69414, Accuracy: 50.25% | Test loss: 0.69455, Test acc: 52.50%\n",
            "Epoch: 70 | Loss: 0.69397, Accuracy: 50.00% | Test loss: 0.69433, Test acc: 52.50%\n",
            "Epoch: 80 | Loss: 0.69382, Accuracy: 50.12% | Test loss: 0.69416, Test acc: 52.50%\n",
            "Epoch: 90 | Loss: 0.69370, Accuracy: 50.00% | Test loss: 0.69402, Test acc: 52.50%\n",
            "Epoch: 100 | Loss: 0.69360, Accuracy: 50.00% | Test loss: 0.69392, Test acc: 52.50%\n",
            "Epoch: 110 | Loss: 0.69352, Accuracy: 49.88% | Test loss: 0.69384, Test acc: 52.50%\n",
            "Epoch: 120 | Loss: 0.69345, Accuracy: 50.12% | Test loss: 0.69378, Test acc: 52.00%\n",
            "Epoch: 130 | Loss: 0.69339, Accuracy: 50.25% | Test loss: 0.69373, Test acc: 51.00%\n",
            "Epoch: 140 | Loss: 0.69333, Accuracy: 50.50% | Test loss: 0.69370, Test acc: 51.00%\n",
            "Epoch: 150 | Loss: 0.69329, Accuracy: 50.62% | Test loss: 0.69367, Test acc: 50.50%\n",
            "Epoch: 160 | Loss: 0.69325, Accuracy: 50.62% | Test loss: 0.69366, Test acc: 50.00%\n",
            "Epoch: 170 | Loss: 0.69321, Accuracy: 50.38% | Test loss: 0.69365, Test acc: 50.00%\n",
            "Epoch: 180 | Loss: 0.69318, Accuracy: 50.00% | Test loss: 0.69365, Test acc: 49.50%\n",
            "Epoch: 190 | Loss: 0.69315, Accuracy: 50.00% | Test loss: 0.69365, Test acc: 49.00%\n",
            "Epoch: 200 | Loss: 0.69312, Accuracy: 50.25% | Test loss: 0.69366, Test acc: 48.00%\n",
            "Epoch: 210 | Loss: 0.69310, Accuracy: 50.00% | Test loss: 0.69367, Test acc: 48.00%\n",
            "Epoch: 220 | Loss: 0.69308, Accuracy: 50.12% | Test loss: 0.69368, Test acc: 47.50%\n",
            "Epoch: 230 | Loss: 0.69306, Accuracy: 49.50% | Test loss: 0.69369, Test acc: 48.00%\n",
            "Epoch: 240 | Loss: 0.69305, Accuracy: 49.75% | Test loss: 0.69370, Test acc: 48.00%\n",
            "Epoch: 250 | Loss: 0.69303, Accuracy: 49.38% | Test loss: 0.69372, Test acc: 47.50%\n",
            "Epoch: 260 | Loss: 0.69302, Accuracy: 49.88% | Test loss: 0.69373, Test acc: 47.00%\n",
            "Epoch: 270 | Loss: 0.69301, Accuracy: 49.50% | Test loss: 0.69375, Test acc: 46.00%\n",
            "Epoch: 280 | Loss: 0.69300, Accuracy: 49.88% | Test loss: 0.69377, Test acc: 46.50%\n",
            "Epoch: 290 | Loss: 0.69299, Accuracy: 49.75% | Test loss: 0.69379, Test acc: 48.00%\n",
            "Epoch: 300 | Loss: 0.69298, Accuracy: 50.12% | Test loss: 0.69380, Test acc: 47.50%\n",
            "Epoch: 310 | Loss: 0.69297, Accuracy: 50.12% | Test loss: 0.69382, Test acc: 47.50%\n",
            "Epoch: 320 | Loss: 0.69297, Accuracy: 50.00% | Test loss: 0.69384, Test acc: 48.00%\n",
            "Epoch: 330 | Loss: 0.69296, Accuracy: 50.25% | Test loss: 0.69385, Test acc: 48.00%\n",
            "Epoch: 340 | Loss: 0.69295, Accuracy: 50.38% | Test loss: 0.69387, Test acc: 47.50%\n",
            "Epoch: 350 | Loss: 0.69295, Accuracy: 50.38% | Test loss: 0.69389, Test acc: 47.50%\n",
            "Epoch: 360 | Loss: 0.69294, Accuracy: 50.62% | Test loss: 0.69390, Test acc: 47.00%\n",
            "Epoch: 370 | Loss: 0.69294, Accuracy: 50.38% | Test loss: 0.69392, Test acc: 47.50%\n",
            "Epoch: 380 | Loss: 0.69294, Accuracy: 50.75% | Test loss: 0.69393, Test acc: 48.00%\n",
            "Epoch: 390 | Loss: 0.69293, Accuracy: 50.62% | Test loss: 0.69395, Test acc: 48.00%\n",
            "Epoch: 400 | Loss: 0.69293, Accuracy: 50.88% | Test loss: 0.69396, Test acc: 48.00%\n",
            "Epoch: 410 | Loss: 0.69293, Accuracy: 51.38% | Test loss: 0.69397, Test acc: 48.00%\n",
            "Epoch: 420 | Loss: 0.69292, Accuracy: 51.62% | Test loss: 0.69399, Test acc: 48.00%\n",
            "Epoch: 430 | Loss: 0.69292, Accuracy: 52.12% | Test loss: 0.69400, Test acc: 48.00%\n",
            "Epoch: 440 | Loss: 0.69292, Accuracy: 51.88% | Test loss: 0.69401, Test acc: 48.00%\n",
            "Epoch: 450 | Loss: 0.69292, Accuracy: 51.88% | Test loss: 0.69402, Test acc: 48.50%\n",
            "Epoch: 460 | Loss: 0.69292, Accuracy: 51.88% | Test loss: 0.69403, Test acc: 48.50%\n",
            "Epoch: 470 | Loss: 0.69292, Accuracy: 52.00% | Test loss: 0.69404, Test acc: 48.50%\n",
            "Epoch: 480 | Loss: 0.69291, Accuracy: 51.88% | Test loss: 0.69406, Test acc: 49.00%\n",
            "Epoch: 490 | Loss: 0.69291, Accuracy: 51.75% | Test loss: 0.69407, Test acc: 49.00%\n",
            "Epoch: 500 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69407, Test acc: 49.50%\n",
            "Epoch: 510 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69408, Test acc: 49.50%\n",
            "Epoch: 520 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69409, Test acc: 49.50%\n",
            "Epoch: 530 | Loss: 0.69291, Accuracy: 51.75% | Test loss: 0.69410, Test acc: 50.00%\n",
            "Epoch: 540 | Loss: 0.69291, Accuracy: 51.88% | Test loss: 0.69411, Test acc: 50.00%\n",
            "Epoch: 550 | Loss: 0.69291, Accuracy: 51.88% | Test loss: 0.69412, Test acc: 50.00%\n",
            "Epoch: 560 | Loss: 0.69291, Accuracy: 52.12% | Test loss: 0.69412, Test acc: 50.00%\n",
            "Epoch: 570 | Loss: 0.69291, Accuracy: 52.25% | Test loss: 0.69413, Test acc: 50.00%\n",
            "Epoch: 580 | Loss: 0.69291, Accuracy: 52.25% | Test loss: 0.69414, Test acc: 50.00%\n",
            "Epoch: 590 | Loss: 0.69291, Accuracy: 52.12% | Test loss: 0.69414, Test acc: 50.00%\n",
            "Epoch: 600 | Loss: 0.69291, Accuracy: 52.25% | Test loss: 0.69415, Test acc: 50.00%\n",
            "Epoch: 610 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69415, Test acc: 50.00%\n",
            "Epoch: 620 | Loss: 0.69291, Accuracy: 52.12% | Test loss: 0.69416, Test acc: 49.50%\n",
            "Epoch: 630 | Loss: 0.69290, Accuracy: 51.88% | Test loss: 0.69416, Test acc: 49.00%\n",
            "Epoch: 640 | Loss: 0.69290, Accuracy: 52.12% | Test loss: 0.69417, Test acc: 49.00%\n",
            "Epoch: 650 | Loss: 0.69290, Accuracy: 52.12% | Test loss: 0.69417, Test acc: 49.00%\n",
            "Epoch: 660 | Loss: 0.69290, Accuracy: 52.12% | Test loss: 0.69418, Test acc: 49.00%\n",
            "Epoch: 670 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69418, Test acc: 48.50%\n",
            "Epoch: 680 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69419, Test acc: 48.50%\n",
            "Epoch: 690 | Loss: 0.69290, Accuracy: 52.25% | Test loss: 0.69419, Test acc: 48.50%\n",
            "Epoch: 700 | Loss: 0.69290, Accuracy: 52.25% | Test loss: 0.69419, Test acc: 48.50%\n",
            "Epoch: 710 | Loss: 0.69290, Accuracy: 52.25% | Test loss: 0.69420, Test acc: 48.00%\n",
            "Epoch: 720 | Loss: 0.69290, Accuracy: 52.12% | Test loss: 0.69420, Test acc: 48.00%\n",
            "Epoch: 730 | Loss: 0.69290, Accuracy: 52.12% | Test loss: 0.69420, Test acc: 48.50%\n",
            "Epoch: 740 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69421, Test acc: 48.00%\n",
            "Epoch: 750 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69421, Test acc: 48.00%\n",
            "Epoch: 760 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69421, Test acc: 48.00%\n",
            "Epoch: 770 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69421, Test acc: 48.00%\n",
            "Epoch: 780 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69422, Test acc: 48.00%\n",
            "Epoch: 790 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69422, Test acc: 48.00%\n",
            "Epoch: 800 | Loss: 0.69290, Accuracy: 51.88% | Test loss: 0.69422, Test acc: 48.00%\n",
            "Epoch: 810 | Loss: 0.69290, Accuracy: 51.88% | Test loss: 0.69422, Test acc: 48.00%\n",
            "Epoch: 820 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69423, Test acc: 48.00%\n",
            "Epoch: 830 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69423, Test acc: 48.00%\n",
            "Epoch: 840 | Loss: 0.69290, Accuracy: 52.12% | Test loss: 0.69423, Test acc: 48.50%\n",
            "Epoch: 850 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69423, Test acc: 48.50%\n",
            "Epoch: 860 | Loss: 0.69290, Accuracy: 51.88% | Test loss: 0.69423, Test acc: 48.50%\n",
            "Epoch: 870 | Loss: 0.69290, Accuracy: 51.88% | Test loss: 0.69423, Test acc: 48.50%\n",
            "Epoch: 880 | Loss: 0.69290, Accuracy: 51.88% | Test loss: 0.69424, Test acc: 48.50%\n",
            "Epoch: 890 | Loss: 0.69290, Accuracy: 51.88% | Test loss: 0.69424, Test acc: 48.50%\n",
            "Epoch: 900 | Loss: 0.69290, Accuracy: 51.88% | Test loss: 0.69424, Test acc: 48.50%\n",
            "Epoch: 910 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69424, Test acc: 48.50%\n",
            "Epoch: 920 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69424, Test acc: 48.50%\n",
            "Epoch: 930 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69424, Test acc: 48.50%\n",
            "Epoch: 940 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69424, Test acc: 48.50%\n",
            "Epoch: 950 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69424, Test acc: 48.50%\n",
            "Epoch: 960 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69424, Test acc: 48.50%\n",
            "Epoch: 970 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69425, Test acc: 48.50%\n",
            "Epoch: 980 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69425, Test acc: 48.50%\n",
            "Epoch: 990 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69425, Test acc: 48.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JY72yQWUZT-s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}