{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAGIGy8EG7R8eVKza+JNRi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickygrosvenor-pramanick/learn-ml/blob/main/pytorch/nn_workflow_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RycF4CzogF8e"
      },
      "outputs": [],
      "source": [
        "# Create Dataset\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "X, y = make_circles(n_samples=1000,\n",
        "                    noise=0.7,\n",
        "                    factor=0.8,\n",
        "                    random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Tensors\n",
        "import torch\n",
        "\n",
        "X = torch.from_numpy(X).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.float)"
      ],
      "metadata": {
        "id": "saSwPWAQgrGr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TaBKyDVBg-BX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agnostic Code\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "KVIAfeXBhWHr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigate Data Format\n",
        "# X gives 2 numbers as input, y returns 1 number as output\n",
        "X_train[:5], y_train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Ts3pSah9Di",
        "outputId": "ac329337-e072-414b-e097-63af647e0d2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.3037,  0.1872],\n",
              "         [-0.3370, -0.6710],\n",
              "         [-1.4545,  0.4610],\n",
              "         [-0.7890, -0.2558],\n",
              "         [-0.0992,  1.1932]]),\n",
              " tensor([1., 0., 0., 0., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model Class\n",
        "class CircleModelV1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(in_features=2, out_features=8)\n",
        "    self.layer_2 = nn.Linear(in_features=8, out_features=3)\n",
        "    self.layer_3 = nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_3(self.layer_2(self.layer_1(x)))"
      ],
      "metadata": {
        "id": "SOjC6JMchlBh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model Instance\n",
        "model1 = CircleModelV1().to(device)\n",
        "model1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_7zDS6sitO2",
        "outputId": "b8ba6afc-0d1e-4046-db45-22e3c1f1ced9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CircleModelV1(\n",
              "  (layer_1): Linear(in_features=2, out_features=8, bias=True)\n",
              "  (layer_2): Linear(in_features=8, out_features=3, bias=True)\n",
              "  (layer_3): Linear(in_features=3, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial Predictions without Training\n",
        "import math\n",
        "with torch.inference_mode():\n",
        "  untrained_preds = model1(X_test.to(device))\n",
        "untrained_preds[:5], y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Rkgb8Gi1_d",
        "outputId": "fde56574-d55e-44fe-8241-3bcfe8b32646"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0597],\n",
              "         [-0.1511],\n",
              "         [-0.0253],\n",
              "         [-0.1848],\n",
              "         [ 0.1243]]),\n",
              " tensor([1., 0., 1., 0., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a loss function\n",
        "\n",
        "# For Regression, you may want MSE or MAE\n",
        "# For Classification, Binary Cross Entropy or Categorical Cross Entropy\n",
        "loss_fn = nn.BCELoss() # requires inputs to have gone through the sigmoid activation function prior to input\n",
        "\n",
        "# loss_fn = nn.BCEWithLogitsLoss() # has sigmoid activation function built in\n",
        "# This is somewhat similar to\n",
        "# nn.Sequential(\n",
        "#     nn.Sigmoid(),\n",
        "#     nn.BCELoss()\n",
        "# )\n",
        "# nn.BCEWithLogitsLoss() is more numerically stable than plain nn.Sigmoid->nn.BCELoss but we'll do it the other way\n",
        "# to get a sense of the work better\n",
        "\n",
        "optimiser = torch.optim.SGD(params=model1.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "o87Aw9o6Zy_x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters getting updated by SGD\n",
        "model1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbAepHKO0a2I",
        "outputId": "01b93daa-c742-4c8f-b0c8-800ab0ec000e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer_1.weight',\n",
              "              tensor([[-0.7015,  0.2477],\n",
              "                      [-0.5769,  0.2338],\n",
              "                      [-0.0068, -0.4723],\n",
              "                      [ 0.6968,  0.6700],\n",
              "                      [ 0.5463, -0.0156],\n",
              "                      [ 0.2063,  0.5656],\n",
              "                      [-0.6739,  0.4205],\n",
              "                      [ 0.2840, -0.3270]])),\n",
              "             ('layer_1.bias',\n",
              "              tensor([-0.6278, -0.0966,  0.6565, -0.3960, -0.6639, -0.2961, -0.4961, -0.3444])),\n",
              "             ('layer_2.weight',\n",
              "              tensor([[ 0.0267, -0.1080, -0.0367, -0.3084, -0.0355, -0.1487,  0.0841,  0.0495],\n",
              "                      [ 0.3295, -0.1881, -0.1290,  0.1139,  0.2046,  0.1752, -0.0825, -0.1018],\n",
              "                      [ 0.0041,  0.3091, -0.0850,  0.2778,  0.0381, -0.0170, -0.2706,  0.0139]])),\n",
              "             ('layer_2.bias', tensor([ 0.2209, -0.2496,  0.1584])),\n",
              "             ('layer_3.weight', tensor([[ 0.1097,  0.0277, -0.2358]])),\n",
              "             ('layer_3.bias', tensor([-0.0321]))])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.tensor([1, 2, 3])\n",
        "tensor2 = torch.tensor([1, 9, 3])\n",
        "torch.eq(tensor1, tensor2).sum(), torch.eq(tensor1, tensor2).sum().item(), torch.eq(tensor1, tensor2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJr6NKeOQK64",
        "outputId": "873fd8bb-4ad3-462c-e5cd-3dd059bd8692"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2), 2, tensor([ True, False,  True]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Accuracy Function - https://www.youtube.com/watch?v=RYFViaaJxE8&ab_channel=MathsResource as a Percentage\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  accuracy = (correct/len(y_pred)) * 100\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "ky81QeJd0diY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "\n",
        "# Logits are the raw outputs of our models - output from the forward() function of our model class.\n",
        "# We want to go from logits -> prediction probabilities -> prediction label\n",
        "\n",
        "# We can convert Logits into Prediction Probabilities by passing them through an activation function\n",
        "# Generally sigmoid for binary classification and softmax for multiclass classification\n",
        "\n",
        "# Logits from Model Output\n",
        "y_logits = model1(X_test.to(device))\n",
        "\n",
        "# Pass through Sigmoid Function to get Prediction Probabilities\n",
        "y_pred_probs = torch.sigmoid(y_logits)\n",
        "\n",
        "# Round the Prediction Probabilities to get Classification Category or Prediction Label.\n",
        "y_preds = torch.round(y_pred_probs)\n",
        "y_preds[:5], y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrFSE7SkQTz0",
        "outputId": "9c251479-f107-4d74-c061-f38925e9a528"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [1.]], grad_fn=<SliceBackward0>),\n",
              " tensor([1., 0., 1., 0., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As seen from above, y_preds has an extra redundant dimension\n",
        "y_preds.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gj50IhlUVo2",
        "outputId": "15bf7041-4798-46a5-946d-7d48668dc6ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So we squeeze the Tensor\n",
        "y_preds.squeeze()[:5], y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpMKZkOGVQCU",
        "outputId": "17c2d1bb-d141-44d4-8fe8-37b7cf219c16"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 1.], grad_fn=<SliceBackward0>),\n",
              " tensor([1., 0., 1., 0., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a Training and Testing Loop\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "# Put data to target device\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model1.train()\n",
        "\n",
        "  # 1. Forward pass (model outputs raw logits)\n",
        "  y_logits = model1(X_train).squeeze()\n",
        "  y_preds = torch.round(torch.sigmoid(y_logits))\n",
        "\n",
        "  # 2. Calculate loss/accuracy - https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html\n",
        "  loss = loss_fn(torch.sigmoid(y_logits), y_train)\n",
        "  accuracy = accuracy_fn(y_true=y_train, y_pred=y_preds)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimiser.zero_grad()\n",
        "\n",
        "  # 4. Loss backwards\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Optimizer step\n",
        "  optimiser.step()\n",
        "\n",
        "  ### Testing\n",
        "  model1.eval()\n",
        "  with torch.inference_mode():\n",
        "    # 1. Forward pass\n",
        "    test_logits = model1(X_test).squeeze()\n",
        "    test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "\n",
        "    # 2. Calculate loss/accuracy\n",
        "    test_loss = loss_fn(torch.sigmoid(test_logits), y_test)\n",
        "    test_accuracy = accuracy_fn(y_true=y_test, y_pred=test_pred)\n",
        "\n",
        "    # Print out what's happening every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {accuracy:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4wMJd2lVVhV",
        "outputId": "5530c07e-fd2c-4043-ef2a-67808d4191a1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.69430, Accuracy: 49.50% | Test loss: 0.69251, Test acc: 54.00%\n",
            "Epoch: 10 | Loss: 0.69413, Accuracy: 49.75% | Test loss: 0.69248, Test acc: 53.50%\n",
            "Epoch: 20 | Loss: 0.69399, Accuracy: 49.25% | Test loss: 0.69247, Test acc: 53.00%\n",
            "Epoch: 30 | Loss: 0.69387, Accuracy: 49.38% | Test loss: 0.69248, Test acc: 53.00%\n",
            "Epoch: 40 | Loss: 0.69377, Accuracy: 49.12% | Test loss: 0.69250, Test acc: 53.50%\n",
            "Epoch: 50 | Loss: 0.69368, Accuracy: 49.50% | Test loss: 0.69252, Test acc: 54.00%\n",
            "Epoch: 60 | Loss: 0.69360, Accuracy: 49.50% | Test loss: 0.69255, Test acc: 54.00%\n",
            "Epoch: 70 | Loss: 0.69354, Accuracy: 49.38% | Test loss: 0.69258, Test acc: 54.00%\n",
            "Epoch: 80 | Loss: 0.69348, Accuracy: 49.50% | Test loss: 0.69261, Test acc: 54.00%\n",
            "Epoch: 90 | Loss: 0.69343, Accuracy: 49.38% | Test loss: 0.69264, Test acc: 54.00%\n",
            "Epoch: 100 | Loss: 0.69338, Accuracy: 48.75% | Test loss: 0.69268, Test acc: 53.50%\n",
            "Epoch: 110 | Loss: 0.69334, Accuracy: 48.50% | Test loss: 0.69271, Test acc: 54.00%\n",
            "Epoch: 120 | Loss: 0.69331, Accuracy: 48.50% | Test loss: 0.69275, Test acc: 54.00%\n",
            "Epoch: 130 | Loss: 0.69327, Accuracy: 48.25% | Test loss: 0.69278, Test acc: 53.50%\n",
            "Epoch: 140 | Loss: 0.69324, Accuracy: 48.62% | Test loss: 0.69282, Test acc: 52.00%\n",
            "Epoch: 150 | Loss: 0.69322, Accuracy: 48.88% | Test loss: 0.69285, Test acc: 51.50%\n",
            "Epoch: 160 | Loss: 0.69320, Accuracy: 48.75% | Test loss: 0.69288, Test acc: 51.50%\n",
            "Epoch: 170 | Loss: 0.69317, Accuracy: 48.62% | Test loss: 0.69292, Test acc: 51.00%\n",
            "Epoch: 180 | Loss: 0.69315, Accuracy: 48.50% | Test loss: 0.69295, Test acc: 51.50%\n",
            "Epoch: 190 | Loss: 0.69314, Accuracy: 49.00% | Test loss: 0.69298, Test acc: 52.00%\n",
            "Epoch: 200 | Loss: 0.69312, Accuracy: 48.75% | Test loss: 0.69301, Test acc: 51.00%\n",
            "Epoch: 210 | Loss: 0.69311, Accuracy: 48.75% | Test loss: 0.69304, Test acc: 50.50%\n",
            "Epoch: 220 | Loss: 0.69309, Accuracy: 49.00% | Test loss: 0.69307, Test acc: 51.00%\n",
            "Epoch: 230 | Loss: 0.69308, Accuracy: 49.38% | Test loss: 0.69310, Test acc: 51.00%\n",
            "Epoch: 240 | Loss: 0.69307, Accuracy: 49.25% | Test loss: 0.69313, Test acc: 51.50%\n",
            "Epoch: 250 | Loss: 0.69306, Accuracy: 49.25% | Test loss: 0.69316, Test acc: 50.50%\n",
            "Epoch: 260 | Loss: 0.69305, Accuracy: 49.50% | Test loss: 0.69319, Test acc: 51.50%\n",
            "Epoch: 270 | Loss: 0.69304, Accuracy: 49.25% | Test loss: 0.69321, Test acc: 50.00%\n",
            "Epoch: 280 | Loss: 0.69303, Accuracy: 49.00% | Test loss: 0.69324, Test acc: 48.50%\n",
            "Epoch: 290 | Loss: 0.69303, Accuracy: 49.00% | Test loss: 0.69326, Test acc: 48.50%\n",
            "Epoch: 300 | Loss: 0.69302, Accuracy: 49.25% | Test loss: 0.69329, Test acc: 48.00%\n",
            "Epoch: 310 | Loss: 0.69301, Accuracy: 50.00% | Test loss: 0.69331, Test acc: 48.50%\n",
            "Epoch: 320 | Loss: 0.69301, Accuracy: 50.38% | Test loss: 0.69333, Test acc: 49.50%\n",
            "Epoch: 330 | Loss: 0.69300, Accuracy: 50.25% | Test loss: 0.69336, Test acc: 49.00%\n",
            "Epoch: 340 | Loss: 0.69300, Accuracy: 50.25% | Test loss: 0.69338, Test acc: 49.50%\n",
            "Epoch: 350 | Loss: 0.69299, Accuracy: 50.00% | Test loss: 0.69340, Test acc: 49.00%\n",
            "Epoch: 360 | Loss: 0.69299, Accuracy: 49.75% | Test loss: 0.69342, Test acc: 49.00%\n",
            "Epoch: 370 | Loss: 0.69298, Accuracy: 50.38% | Test loss: 0.69344, Test acc: 49.50%\n",
            "Epoch: 380 | Loss: 0.69298, Accuracy: 50.38% | Test loss: 0.69346, Test acc: 48.00%\n",
            "Epoch: 390 | Loss: 0.69297, Accuracy: 50.00% | Test loss: 0.69348, Test acc: 49.00%\n",
            "Epoch: 400 | Loss: 0.69297, Accuracy: 50.25% | Test loss: 0.69350, Test acc: 49.50%\n",
            "Epoch: 410 | Loss: 0.69297, Accuracy: 50.25% | Test loss: 0.69352, Test acc: 50.00%\n",
            "Epoch: 420 | Loss: 0.69296, Accuracy: 50.25% | Test loss: 0.69353, Test acc: 49.50%\n",
            "Epoch: 430 | Loss: 0.69296, Accuracy: 49.88% | Test loss: 0.69355, Test acc: 49.00%\n",
            "Epoch: 440 | Loss: 0.69296, Accuracy: 50.50% | Test loss: 0.69357, Test acc: 49.50%\n",
            "Epoch: 450 | Loss: 0.69296, Accuracy: 51.12% | Test loss: 0.69358, Test acc: 49.50%\n",
            "Epoch: 460 | Loss: 0.69295, Accuracy: 50.88% | Test loss: 0.69360, Test acc: 49.50%\n",
            "Epoch: 470 | Loss: 0.69295, Accuracy: 51.62% | Test loss: 0.69362, Test acc: 49.50%\n",
            "Epoch: 480 | Loss: 0.69295, Accuracy: 51.75% | Test loss: 0.69363, Test acc: 49.50%\n",
            "Epoch: 490 | Loss: 0.69295, Accuracy: 51.88% | Test loss: 0.69365, Test acc: 49.50%\n",
            "Epoch: 500 | Loss: 0.69294, Accuracy: 51.88% | Test loss: 0.69366, Test acc: 49.00%\n",
            "Epoch: 510 | Loss: 0.69294, Accuracy: 51.75% | Test loss: 0.69368, Test acc: 49.00%\n",
            "Epoch: 520 | Loss: 0.69294, Accuracy: 51.88% | Test loss: 0.69369, Test acc: 49.00%\n",
            "Epoch: 530 | Loss: 0.69294, Accuracy: 51.88% | Test loss: 0.69370, Test acc: 49.00%\n",
            "Epoch: 540 | Loss: 0.69294, Accuracy: 51.62% | Test loss: 0.69372, Test acc: 49.50%\n",
            "Epoch: 550 | Loss: 0.69294, Accuracy: 51.62% | Test loss: 0.69373, Test acc: 49.50%\n",
            "Epoch: 560 | Loss: 0.69293, Accuracy: 51.50% | Test loss: 0.69374, Test acc: 49.50%\n",
            "Epoch: 570 | Loss: 0.69293, Accuracy: 51.50% | Test loss: 0.69375, Test acc: 49.50%\n",
            "Epoch: 580 | Loss: 0.69293, Accuracy: 51.75% | Test loss: 0.69377, Test acc: 49.50%\n",
            "Epoch: 590 | Loss: 0.69293, Accuracy: 51.75% | Test loss: 0.69378, Test acc: 49.50%\n",
            "Epoch: 600 | Loss: 0.69293, Accuracy: 51.62% | Test loss: 0.69379, Test acc: 49.00%\n",
            "Epoch: 610 | Loss: 0.69293, Accuracy: 51.50% | Test loss: 0.69380, Test acc: 49.50%\n",
            "Epoch: 620 | Loss: 0.69293, Accuracy: 51.88% | Test loss: 0.69381, Test acc: 49.50%\n",
            "Epoch: 630 | Loss: 0.69293, Accuracy: 52.00% | Test loss: 0.69382, Test acc: 50.00%\n",
            "Epoch: 640 | Loss: 0.69292, Accuracy: 52.12% | Test loss: 0.69383, Test acc: 50.00%\n",
            "Epoch: 650 | Loss: 0.69292, Accuracy: 52.00% | Test loss: 0.69384, Test acc: 50.00%\n",
            "Epoch: 660 | Loss: 0.69292, Accuracy: 52.00% | Test loss: 0.69385, Test acc: 50.00%\n",
            "Epoch: 670 | Loss: 0.69292, Accuracy: 51.88% | Test loss: 0.69386, Test acc: 50.00%\n",
            "Epoch: 680 | Loss: 0.69292, Accuracy: 51.75% | Test loss: 0.69387, Test acc: 50.00%\n",
            "Epoch: 690 | Loss: 0.69292, Accuracy: 51.88% | Test loss: 0.69388, Test acc: 49.50%\n",
            "Epoch: 700 | Loss: 0.69292, Accuracy: 51.75% | Test loss: 0.69389, Test acc: 50.00%\n",
            "Epoch: 710 | Loss: 0.69292, Accuracy: 51.88% | Test loss: 0.69390, Test acc: 50.00%\n",
            "Epoch: 720 | Loss: 0.69292, Accuracy: 51.88% | Test loss: 0.69391, Test acc: 50.00%\n",
            "Epoch: 730 | Loss: 0.69292, Accuracy: 52.00% | Test loss: 0.69392, Test acc: 49.50%\n",
            "Epoch: 740 | Loss: 0.69292, Accuracy: 51.75% | Test loss: 0.69392, Test acc: 49.50%\n",
            "Epoch: 750 | Loss: 0.69292, Accuracy: 51.88% | Test loss: 0.69393, Test acc: 49.50%\n",
            "Epoch: 760 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69394, Test acc: 49.50%\n",
            "Epoch: 770 | Loss: 0.69291, Accuracy: 52.12% | Test loss: 0.69395, Test acc: 49.50%\n",
            "Epoch: 780 | Loss: 0.69291, Accuracy: 52.12% | Test loss: 0.69396, Test acc: 49.50%\n",
            "Epoch: 790 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69396, Test acc: 49.50%\n",
            "Epoch: 800 | Loss: 0.69291, Accuracy: 52.12% | Test loss: 0.69397, Test acc: 49.50%\n",
            "Epoch: 810 | Loss: 0.69291, Accuracy: 52.12% | Test loss: 0.69398, Test acc: 49.50%\n",
            "Epoch: 820 | Loss: 0.69291, Accuracy: 52.12% | Test loss: 0.69398, Test acc: 49.50%\n",
            "Epoch: 830 | Loss: 0.69291, Accuracy: 52.12% | Test loss: 0.69399, Test acc: 49.50%\n",
            "Epoch: 840 | Loss: 0.69291, Accuracy: 52.12% | Test loss: 0.69400, Test acc: 48.50%\n",
            "Epoch: 850 | Loss: 0.69291, Accuracy: 51.88% | Test loss: 0.69400, Test acc: 48.50%\n",
            "Epoch: 860 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69401, Test acc: 48.50%\n",
            "Epoch: 870 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69402, Test acc: 48.50%\n",
            "Epoch: 880 | Loss: 0.69291, Accuracy: 51.88% | Test loss: 0.69402, Test acc: 48.50%\n",
            "Epoch: 890 | Loss: 0.69291, Accuracy: 51.88% | Test loss: 0.69403, Test acc: 48.50%\n",
            "Epoch: 900 | Loss: 0.69291, Accuracy: 51.88% | Test loss: 0.69403, Test acc: 48.00%\n",
            "Epoch: 910 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69404, Test acc: 48.00%\n",
            "Epoch: 920 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69405, Test acc: 48.00%\n",
            "Epoch: 930 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69405, Test acc: 48.00%\n",
            "Epoch: 940 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69406, Test acc: 48.00%\n",
            "Epoch: 950 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69406, Test acc: 48.00%\n",
            "Epoch: 960 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69407, Test acc: 48.00%\n",
            "Epoch: 970 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69407, Test acc: 48.00%\n",
            "Epoch: 980 | Loss: 0.69291, Accuracy: 51.88% | Test loss: 0.69408, Test acc: 48.00%\n",
            "Epoch: 990 | Loss: 0.69291, Accuracy: 51.75% | Test loss: 0.69408, Test acc: 48.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improving Our Model\n",
        "\n",
        "# Add More Layers\n",
        "# Add More Hidden Units\n",
        "# Fit for Longer with More Epochs\n",
        "# Change/Add Activation Functions\n",
        "# Change the Learning Rate\n",
        "# Change the Loss Function\n",
        "# Use Transfer Learning\n",
        "\n",
        "# Making a new and larger model\n",
        "class CircleModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(in_features=2, out_features=8)\n",
        "    self.layer_2 = nn.Linear(in_features=8, out_features=8)\n",
        "    self.layer_3 = nn.Linear(in_features=8, out_features=64)\n",
        "    self.layer_4 = nn.Linear(in_features=64, out_features=256)\n",
        "    self.layer_5 = nn.Linear(in_features=256, out_features=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_5(self.layer_4(self.layer_3(self.layer_2(self.layer_1(x)))))"
      ],
      "metadata": {
        "id": "JY72yQWUZT-s"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of our model\n",
        "model2 = CircleModelV2().to(device)\n",
        "model2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLf0i2GmnR2_",
        "outputId": "473342d7-b7b5-4d2b-842a-4a39dc30d656"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CircleModelV2(\n",
              "  (layer_1): Linear(in_features=2, out_features=8, bias=True)\n",
              "  (layer_2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (layer_3): Linear(in_features=8, out_features=64, bias=True)\n",
              "  (layer_4): Linear(in_features=64, out_features=256, bias=True)\n",
              "  (layer_5): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up loss and optimiser functions\n",
        "loss_fn = nn.BCEWithLogitsLoss() # Does not require sigmoid on input\n",
        "optimiser = torch.optim.SGD(model2.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "mCUI2WIanwUW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Testing\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "# Put data into device\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model2.train()\n",
        "\n",
        "  y_logits = model2(X_train).squeeze()\n",
        "  y_preds = torch.round(torch.sigmoid(y_logits))\n",
        "\n",
        "  loss = loss_fn(y_logits, y_train)\n",
        "  accuracy = accuracy_fn(y_true=y_train, y_pred=y_preds)\n",
        "\n",
        "  optimiser.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimiser.step()\n",
        "\n",
        "  model2.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_logits = model2(X_test).squeeze()\n",
        "    test_preds = torch.round(torch.sigmoid(test_logits))\n",
        "\n",
        "    test_loss = loss_fn(test_logits, y_test)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {accuracy:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBeZcgVzn30X",
        "outputId": "715fea8b-dc87-4684-f6a6-619df6bd9650"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.69375, Accuracy: 49.00% | Test loss: 0.69320, Test acc: 48.00%\n",
            "Epoch: 10 | Loss: 0.69318, Accuracy: 50.75% | Test loss: 0.69339, Test acc: 48.00%\n",
            "Epoch: 20 | Loss: 0.69305, Accuracy: 51.00% | Test loss: 0.69355, Test acc: 48.00%\n",
            "Epoch: 30 | Loss: 0.69298, Accuracy: 51.75% | Test loss: 0.69369, Test acc: 48.00%\n",
            "Epoch: 40 | Loss: 0.69294, Accuracy: 52.62% | Test loss: 0.69381, Test acc: 48.00%\n",
            "Epoch: 50 | Loss: 0.69292, Accuracy: 52.00% | Test loss: 0.69391, Test acc: 48.00%\n",
            "Epoch: 60 | Loss: 0.69291, Accuracy: 51.75% | Test loss: 0.69399, Test acc: 48.00%\n",
            "Epoch: 70 | Loss: 0.69291, Accuracy: 52.00% | Test loss: 0.69405, Test acc: 48.00%\n",
            "Epoch: 80 | Loss: 0.69291, Accuracy: 52.25% | Test loss: 0.69410, Test acc: 48.00%\n",
            "Epoch: 90 | Loss: 0.69290, Accuracy: 52.00% | Test loss: 0.69414, Test acc: 48.00%\n",
            "Epoch: 100 | Loss: 0.69290, Accuracy: 52.38% | Test loss: 0.69417, Test acc: 48.00%\n",
            "Epoch: 110 | Loss: 0.69290, Accuracy: 52.12% | Test loss: 0.69419, Test acc: 48.00%\n",
            "Epoch: 120 | Loss: 0.69290, Accuracy: 51.88% | Test loss: 0.69421, Test acc: 48.00%\n",
            "Epoch: 130 | Loss: 0.69290, Accuracy: 51.88% | Test loss: 0.69422, Test acc: 48.00%\n",
            "Epoch: 140 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69423, Test acc: 48.00%\n",
            "Epoch: 150 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69424, Test acc: 48.00%\n",
            "Epoch: 160 | Loss: 0.69290, Accuracy: 51.62% | Test loss: 0.69424, Test acc: 48.00%\n",
            "Epoch: 170 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69425, Test acc: 48.00%\n",
            "Epoch: 180 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69425, Test acc: 48.00%\n",
            "Epoch: 190 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69425, Test acc: 48.00%\n",
            "Epoch: 200 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 210 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 220 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 230 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 240 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 250 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 260 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 270 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 280 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 290 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 300 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 310 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 320 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 330 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 340 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 350 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 360 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 370 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 380 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 390 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 400 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 410 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 420 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 430 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 440 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 450 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 460 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 470 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 480 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 490 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 500 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 510 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 520 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 530 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 540 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 550 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 560 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 570 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 580 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 590 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 600 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 610 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 620 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 630 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 640 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 650 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 660 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 670 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 680 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 690 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 700 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 710 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 720 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 730 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 740 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 750 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 760 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 770 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 780 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 790 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 800 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 810 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 820 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 830 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 840 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 850 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 860 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 870 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 880 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 890 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 900 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 910 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 920 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 930 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 940 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 950 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 960 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 970 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 980 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n",
            "Epoch: 990 | Loss: 0.69290, Accuracy: 51.75% | Test loss: 0.69426, Test acc: 48.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if our model can model a straight line\n",
        "\n",
        "# Create some data\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.01\n",
        "\n",
        "# Create data\n",
        "X_regression = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y_regression = weight * X_regression + bias # linear regression formula\n",
        "\n",
        "# Check the data\n",
        "print(len(X_regression))\n",
        "X_regression[:5], y_regression[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1yYyJp-p0zO",
        "outputId": "cc919dff-5f4a-4b68-8c9d-9e982cfce963"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0100],\n",
              "         [0.0200],\n",
              "         [0.0300],\n",
              "         [0.0400]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3070],\n",
              "         [0.3140],\n",
              "         [0.3210],\n",
              "         [0.3280]]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test splits\n",
        "train_split = int(0.8 * len(X_regression)) # 80% of data used for training set\n",
        "X_train_regression, y_train_regression = X_regression[:train_split], y_regression[:train_split]\n",
        "X_test_regression, y_test_regression = X_regression[train_split:], y_regression[train_split:]\n",
        "\n",
        "# Check the lengths of each split\n",
        "print(len(X_train_regression),\n",
        "    len(y_train_regression),\n",
        "    len(X_test_regression),\n",
        "    len(y_test_regression))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsOY62ypqkkb",
        "outputId": "a7c8aca3-b1da-4784-b382-99f9aa6d9a55"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80 80 20 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a Neural Network Model (based on ModelV2) fit a Linear Model\n",
        "class CircleModelV3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(in_features=1, out_features=8)\n",
        "    self.layer_2 = nn.Linear(in_features=8, out_features=8)\n",
        "    self.layer_3 = nn.Linear(in_features=8, out_features=64)\n",
        "    self.layer_4 = nn.Linear(in_features=64, out_features=256)\n",
        "    self.layer_5 = nn.Linear(in_features=256, out_features=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_5(self.layer_4(self.layer_3(self.layer_2(self.layer_1(x)))))\n",
        "\n",
        "# Create an instance of our model\n",
        "model2 = CircleModelV3().to(device)\n",
        "model2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCVX-1l6qp45",
        "outputId": "32a188b6-c44a-49cf-f791-70f121f20f2c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CircleModelV3(\n",
              "  (layer_1): Linear(in_features=1, out_features=8, bias=True)\n",
              "  (layer_2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (layer_3): Linear(in_features=8, out_features=64, bias=True)\n",
              "  (layer_4): Linear(in_features=64, out_features=256, bias=True)\n",
              "  (layer_5): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Loss and Optimiser Functions\n",
        "loss_fn = nn.L1Loss() # MAE as this is recommended for regression problems\n",
        "optimiser = torch.optim.SGD(model2.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "2b1A0wKTt2ec"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 1000\n",
        "\n",
        "# Put data to target device\n",
        "X_train_regression, y_train_regression = X_train_regression.to(device), y_train_regression.to(device)\n",
        "X_test_regression, y_test_regression = X_test_regression.to(device), y_test_regression.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model2.train()\n",
        "\n",
        "  ### Training\n",
        "  # 1. Forward pass\n",
        "  y_pred = model2(X_train_regression)\n",
        "\n",
        "  # 2. Calculate loss (no accuracy since it's a regression problem, not classification)\n",
        "  loss = loss_fn(y_pred, y_train_regression)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimiser.zero_grad()\n",
        "\n",
        "  # 4. Loss backwards\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Optimizer step\n",
        "  optimiser.step()\n",
        "\n",
        "  model2.eval()\n",
        "  with torch.inference_mode():\n",
        "    # 1. Forward pass\n",
        "      test_pred = model2(X_test_regression)\n",
        "      # 2. Calculate the loss\n",
        "      test_loss = loss_fn(test_pred, y_test_regression)\n",
        "\n",
        "    # Print out what's happening\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch: {epoch} | Train loss: {loss:.5f}, Test loss: {test_loss:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncAjb6WIuDaC",
        "outputId": "1f30ccba-0332-4fe6-fba7-08a754e9475b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train loss: 0.13953, Test loss: 0.29333\n",
            "Epoch: 100 | Train loss: 0.12165, Test loss: 0.07677\n",
            "Epoch: 200 | Train loss: 0.02563, Test loss: 0.17205\n",
            "Epoch: 300 | Train loss: 0.12919, Test loss: 0.04517\n",
            "Epoch: 400 | Train loss: 0.07161, Test loss: 0.13711\n",
            "Epoch: 500 | Train loss: 0.03098, Test loss: 0.02992\n",
            "Epoch: 600 | Train loss: 0.06223, Test loss: 0.17359\n",
            "Epoch: 700 | Train loss: 0.04451, Test loss: 0.13583\n",
            "Epoch: 800 | Train loss: 0.12093, Test loss: 0.05852\n",
            "Epoch: 900 | Train loss: 0.04118, Test loss: 0.11695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)\n",
        "\n",
        "from helper_functions import plot_predictions, plot_decision_boundary\n",
        "\n",
        "# Turn on evaluation mode\n",
        "model2.eval()\n",
        "\n",
        "# Make predictions (inference)\n",
        "with torch.inference_mode():\n",
        "  y_preds = model2(X_test_regression)\n",
        "\n",
        "# Plot data and predictions with data on the CPU (matplotlib can't handle data on the GPU)\n",
        "# (try removing .cpu() from one of the below and see what happens)\n",
        "plot_predictions(train_data=X_train_regression.cpu(),\n",
        "                 train_labels=y_train_regression.cpu(),\n",
        "                 test_data=X_test_regression.cpu(),\n",
        "                 test_labels=y_test_regression.cpu(),\n",
        "                 predictions=y_preds.cpu());\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "y1b7uAEnuOS-",
        "outputId": "8ee4e954-1adc-4013-80f3-60a3b40fb1c0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helper_functions.py already exists, skipping download\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Alright, it looks like our model is able to do far better than random guessing on straight lines."
      ],
      "metadata": {
        "id": "BpiomCWDuc0z"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0536c5jwGeD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}